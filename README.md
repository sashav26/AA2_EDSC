# AA2_EDSC
Emory Data Science Club baggage prediction project for American Airlines

To interact with Parquet data, use VSCode extension by Lucien Martijn

papers referenced, with gpt descriptions:

1. Entity Embeddings for Categorical Variables
Guo, C., & Berkhahn, F. (2016). Entity Embeddings of Categorical Variables.
arXiv:1604.06737
Used for representing categorical features (e.g., aircraft type) in a dense, learned embedding space.

2. Cyclical Learning Rates for Neural Networks
Smith, L. N. (2017). Cyclical Learning Rates for Training Neural Networks.
arXiv:1506.01186
Justifies dynamic adjustment of the learning rate to improve convergence during training.

3. Revisiting Deep Learning Models for Tabular Data
Gorishniy, S., Rubachev, I., Khrulkov, V., & Babenko, A. (2021). Revisiting Deep Learning Models for Tabular Data.
arXiv:2106.11959
Supports the design of feed-forward architectures (with residual connections, dropout, and batch normalization) as effective for tabular data.

4. Decoupled Weight Decay Regularization (AdamW)
Loshchilov, I., & Hutter, F. (2019). Decoupled Weight Decay Regularization.
arXiv:1711.05101
Provides rationale for using optimizers like AdamW, which improve generalization by decoupling weight decay from the learning rate.

5. Random Search for Hyper-Parameter Optimization
Bergstra, J., & Bengio, Y. (2012). Random Search for Hyper-Parameter Optimization.
Journal of Machine Learning Research, 13, 281â€“305.
Offers insights into effective hyperparameter search strategies, supporting our grid search approach.
